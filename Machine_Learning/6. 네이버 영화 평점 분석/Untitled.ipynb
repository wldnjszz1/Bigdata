{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석\n",
    "\n",
    "사람이 작성한 글이 부정적인지 긍정적인지를 판단하는 예측 모델\n",
    "\n",
    "작성한 글의 형태소를 분석해서 사전을 만들고 출현한 단어나 문장의 횟수를 계산하여 긍정과 부정을 판단한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일단 진선규님께 박수갈채도 부족함 진짜 연기를 다양하게 잘하셔서 놀랐어요 오랜만에 ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관람객류승룡 드디어 심폐소생술 성공!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>관람객진짜 뻥안치고 ㅈㄴ 웃겼다</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>관람객계속 웃으면서 봤어요!\"지금까지 이런맛은 없었다이것은 갈비인가 통닭인가수원왕갈...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지금까지 이런 영화는 없었다  이것은 영화인가 통닭광고인가</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  star\n",
       "0  일단 진선규님께 박수갈채도 부족함 진짜 연기를 다양하게 잘하셔서 놀랐어요 오랜만에 ...    10\n",
       "1                             관람객류승룡 드디어 심폐소생술 성공!       8\n",
       "2                                관람객진짜 뻥안치고 ㅈㄴ 웃겼다      10\n",
       "3  관람객계속 웃으면서 봤어요!\"지금까지 이런맛은 없었다이것은 갈비인가 통닭인가수원왕갈...    10\n",
       "4                 지금까지 이런 영화는 없었다  이것은 영화인가 통닭광고인가      10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('naver_star_data.csv')\n",
    "df.head() # head(): 상위 다섯개만 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    일단 진선규님께 박수갈채도 부족함 진짜 연기를 다양하게 잘하셔서 놀랐어요 오랜만에 ...\n",
       "1                                    류승룡 드디어 심폐소생술 성공!\n",
       "2                                       진짜 뻥안치고 ㅈㄴ 웃겼다\n",
       "3    계속 웃으면서 봤어요!\"지금까지 이런맛은 없었다이것은 갈비인가 통닭인가수원왕갈비통닭...\n",
       "4                     지금까지 이런 영화는 없었다  이것은 영화인가 통닭광고인가\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 후기글 전처리\n",
    "def text_preprocessing(text):\n",
    "    # 관람객이라고 시작하면 관람객을 날려준다\n",
    "    if text.startswith('관람객'):\n",
    "        new_str = text[3:]\n",
    "        return new_str.strip()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df['text'] = df['text'].apply(text_preprocessing) # if문 왜 안쓰는지 ?\n",
    "df['text'].head() # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: star, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평점 데이터 전처리\n",
    "def star_preprocessing(text):\n",
    "    value = int(text)\n",
    "    if value <= 5 :\n",
    "        return '0'\n",
    "    else: return '1'\n",
    "\n",
    "df['star'] = df['star'].apply(star_preprocessing)\n",
    "df['star'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 결과 데이터로 나눈다\n",
    "text_list = df['text'].tolist()\n",
    "star_list = df['star'].tolist()\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 나눈다\n",
    "text_train, text_test, star_train, star_test = train_test_split(text_list, star_list, test_size = 0.3)\n",
    "\n",
    "# 저장한다\n",
    "dic_train = {\n",
    "    'text' : text_train,\n",
    "    'star' : star_train\n",
    "}\n",
    "\n",
    "dic_test = {\n",
    "    'text' : text_test,\n",
    "    'star' : star_test\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(dic_train)\n",
    "df_test = pd.DataFrame(dic_test)\n",
    "\n",
    "df_train.to_csv('movie_train_data.csv', index = False, encoding = 'utf-8-sig')\n",
    "df_test.to_csv('movie_test_data.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kolnpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0213d6bdf3ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkolnpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kolnpy'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 부정인지 긍정인지 학습\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 단어가 얼마나 나오는지 카운트(벡터로 만든 데이터)\n",
    "from sklearn.pipeline import Pipeline # 위에 두 줄을 연결시킴\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kolnpy.tag import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새롭게 저장한 파일을 읽어온다\n",
    "train_df = pd.read_csv('movie_train_data.csv')\n",
    "test_df = pd.read_csv('movie_test_data.csv')\n",
    "\n",
    "# 학습데이터에서 문자열과 긍정/부정값을 분리한다\n",
    "X_train = train_df['text'].tolist()\n",
    "y_train = train_df['star'].tolist()\n",
    "\n",
    "X_test = test_df['text'].tolist()\n",
    "y_test = test_df['star'].tolist()\n",
    "\n",
    "# 문자열 데이터와 결과 데이터를 벡터화 시키는 모델\n",
    "\n",
    "# 형태소 분석을 위한 객체\n",
    "okt = Okt()\n",
    "# 문자열 자르기 하는 함수\n",
    "def tokenizer(text):\n",
    "    return okt.morphs(text)\n",
    "\n",
    "model1 = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "model2 = LogisticRegression(penalty='l2') # 과적합 예방을 해줘야함\n",
    "\n",
    "# 두 모델을 연결한다\n",
    "pipe = Pipeline([('vect', model1), ('clf', model2)])\n",
    "\n",
    "# 학습\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 학습 정확도 측정\n",
    "y_pred = pipe.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f'예측 정확도 : {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "with open('pipe.dat', 'wb') as fp:\n",
    "    pickle.dump(pipe, fp)\n",
    "    \n",
    "print('저장완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 완료된 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe.dat', 'rb') as fp:\n",
    "    pipe = pickle.load(fp)\n",
    "text = ipnut('리뷰를 작성해주세요 : ')\n",
    "\n",
    "str1 = [text]\n",
    "\n",
    "# 예측 정확도 측정\n",
    "r1 = np.max(pipe.predict_proba(str1) * 100)\n",
    "\n",
    "# 예측 결과\n",
    "r2 = pipe.predict(str1)\n",
    "\n",
    "if r2[0] == 1:\n",
    "    print('긍정적인 리뷰')\n",
    "else :\n",
    "    print('부정적인 리뷰')\n",
    "    \n",
    "print(f'정확도 : {r1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
